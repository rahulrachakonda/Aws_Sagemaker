{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar dataset already downloaded\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "utils.cifar10_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the dataset to an S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='/tmp/cifar10_data', key_prefix='data/DEMO-cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "from __future__ import absolute_import\r\n",
      "from __future__ import division\r\n",
      "from __future__ import print_function\r\n",
      "\r\n",
      "import os\r\n",
      "\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.python.keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\r\n",
      "from tensorflow.python.keras.models import Sequential\r\n",
      "from tensorflow.python.saved_model.signature_constants import PREDICT_INPUTS\r\n",
      "from tensorflow.python.training.rmsprop import RMSPropOptimizer\r\n",
      "\r\n",
      "HEIGHT = 32\r\n",
      "WIDTH = 32\r\n",
      "DEPTH = 3\r\n",
      "NUM_CLASSES = 10\r\n",
      "NUM_DATA_BATCHES = 5\r\n",
      "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 10000 * NUM_DATA_BATCHES\r\n",
      "BATCH_SIZE = 40\r\n",
      "INPUT_TENSOR_NAME = 'inputs_input'  # needs to match the name of the first layer + \"_input\"\r\n",
      "\r\n",
      "\r\n",
      "def keras_model_fn(hyperparameters):\r\n",
      "    \r\n",
      "    model = Sequential()\r\n",
      "\r\n",
      "    model.add(Conv2D(32, (3, 3), padding='same', name='inputs', input_shape=(HEIGHT, WIDTH, DEPTH)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Conv2D(32, (3, 3)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
      "    model.add(Dropout(0.25))\r\n",
      "\r\n",
      "    model.add(Conv2D(64, (3, 3), padding='same'))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Conv2D(64, (3, 3)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
      "    model.add(Dropout(0.25))\r\n",
      "    \r\n",
      "    model.add(Conv2D(128, (3, 3), padding='same'))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Conv2D(128, (3, 3)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
      "    model.add(Dropout(0.25))\r\n",
      "    \r\n",
      "\r\n",
      "    model.add(Flatten())\r\n",
      "    model.add(Dense(512))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Dropout(0.5))\r\n",
      "    model.add(Dense(NUM_CLASSES))\r\n",
      "    model.add(Activation('softmax'))\r\n",
      "    \r\n",
      "    opt = RMSPropOptimizer(learning_rate=hyperparameters['learning_rate'], decay=hyperparameters['decay'])\r\n",
      "\r\n",
      "    model.compile(loss='categorical_crossentropy',\r\n",
      "                  optimizer=opt,\r\n",
      "                  metrics=['accuracy'])\r\n",
      "\r\n",
      "    return model\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn(hyperparameters):\r\n",
      "   \r\n",
      "    \r\n",
      "    # Notice that the input placeholder has the same input shape as the Keras model input\r\n",
      "    tensor = tf.placeholder(tf.float32, shape=[None, HEIGHT, WIDTH, DEPTH])\r\n",
      "    \r\n",
      "    # The inputs key INPUT_TENSOR_NAME matches the Keras InputLayer name\r\n",
      "    inputs = {INPUT_TENSOR_NAME: tensor}\r\n",
      "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, hyperparameters):\r\n",
      "    return _input(tf.estimator.ModeKeys.TRAIN,\r\n",
      "                    batch_size=BATCH_SIZE, data_dir=training_dir)\r\n",
      "\r\n",
      "\r\n",
      "def eval_input_fn(training_dir, hyperparameters):\r\n",
      "    return _input(tf.estimator.ModeKeys.EVAL,\r\n",
      "                    batch_size=BATCH_SIZE, data_dir=training_dir)\r\n",
      "\r\n",
      "\r\n",
      "def _input(mode, batch_size, data_dir):\r\n",
      "   \r\n",
      "    dataset = _record_dataset(_filenames(mode, data_dir))\r\n",
      "\r\n",
      "    # For training repeat forever.\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        dataset = dataset.repeat()\r\n",
      "\r\n",
      "    dataset = dataset.map(_dataset_parser)\r\n",
      "    dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "    # For training, preprocess the image and shuffle.\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        dataset = dataset.map(_train_preprocess_fn)\r\n",
      "        dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "        # Ensure that the capacity is sufficiently large to provide good random\r\n",
      "        # shuffling.\r\n",
      "        buffer_size = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4) + 3 * batch_size\r\n",
      "        dataset = dataset.shuffle(buffer_size=buffer_size)\r\n",
      "\r\n",
      "    # Subtract off the mean and divide by the variance of the pixels.\r\n",
      "    dataset = dataset.map(\r\n",
      "        lambda image, label: (tf.image.per_image_standardization(image), label))\r\n",
      "    dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "    # Batch results by up to batch_size, and then fetch the tuple from the\r\n",
      "    # iterator.\r\n",
      "    iterator = dataset.batch(batch_size).make_one_shot_iterator()\r\n",
      "    images, labels = iterator.get_next()\r\n",
      "\r\n",
      "    # We must use the default input tensor name PREDICT_INPUTS\r\n",
      "    return {INPUT_TENSOR_NAME: images}, labels\r\n",
      "\r\n",
      "\r\n",
      "def _train_preprocess_fn(image, label):\r\n",
      "    \"\"\"Preprocess a single training image of layout [height, width, depth].\"\"\"\r\n",
      "    # Resize the image to add four extra pixels on each side.\r\n",
      "    image = tf.image.resize_image_with_crop_or_pad(image, HEIGHT + 8, WIDTH + 8)\r\n",
      "\r\n",
      "    # Randomly crop a [HEIGHT, WIDTH] section of the image.\r\n",
      "    image = tf.random_crop(image, [HEIGHT, WIDTH, DEPTH])\r\n",
      "\r\n",
      "    # Randomly flip the image horizontally.\r\n",
      "    image = tf.image.random_flip_left_right(image)\r\n",
      "\r\n",
      "    return image, label\r\n",
      "\r\n",
      "\r\n",
      "def _dataset_parser(value):\r\n",
      "    \"\"\"Parse a CIFAR-10 record from value.\"\"\"\r\n",
      "    # Every record consists of a label followed by the image, with a fixed number\r\n",
      "    # of bytes for each.\r\n",
      "    label_bytes = 1\r\n",
      "    image_bytes = HEIGHT * WIDTH * DEPTH\r\n",
      "    record_bytes = label_bytes + image_bytes\r\n",
      "\r\n",
      "    # Convert from a string to a vector of uint8 that is record_bytes long.\r\n",
      "    raw_record = tf.decode_raw(value, tf.uint8)\r\n",
      "\r\n",
      "    # The first byte represents the label, which we convert from uint8 to int32.\r\n",
      "    label = tf.cast(raw_record[0], tf.int32)\r\n",
      "\r\n",
      "    # The remaining bytes after the label represent the image, which we reshape\r\n",
      "    # from [depth * height * width] to [depth, height, width].\r\n",
      "    depth_major = tf.reshape(raw_record[label_bytes:record_bytes],\r\n",
      "                             [DEPTH, HEIGHT, WIDTH])\r\n",
      "\r\n",
      "    # Convert from [depth, height, width] to [height, width, depth], and cast as\r\n",
      "    # float32.\r\n",
      "    image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\r\n",
      "\r\n",
      "    return image, tf.one_hot(label, NUM_CLASSES)\r\n",
      "\r\n",
      "\r\n",
      "def _record_dataset(filenames):\r\n",
      "    \"\"\"Returns an input pipeline Dataset from `filenames`.\"\"\"\r\n",
      "    record_bytes = HEIGHT * WIDTH * DEPTH + 1\r\n",
      "    return tf.data.FixedLengthRecordDataset(filenames, record_bytes)\r\n",
      "\r\n",
      "\r\n",
      "def _filenames(mode, data_dir):\r\n",
      "    \"\"\"Returns a list of filenames based on 'mode'.\"\"\"\r\n",
      "    data_dir = os.path.join(data_dir, 'cifar-10-batches-bin')\r\n",
      "\r\n",
      "    assert os.path.exists(data_dir), ('Run cifar10_download_and_extract.py first '\r\n",
      "                                      'to download and extract the CIFAR-10 data.')\r\n",
      "\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        return [\r\n",
      "            os.path.join(data_dir, 'data_batch_%d.bin' % i)\r\n",
      "            for i in range(1, NUM_DATA_BATCHES + 1)\r\n",
      "        ]\r\n",
      "    elif mode == tf.estimator.ModeKeys.EVAL:\r\n",
      "        return [os.path.join(data_dir, 'test_batch.bin')]\r\n",
      "    else:\r\n",
      "        raise ValueError('Invalid mode: %s' % mode)\r\n"
     ]
    }
   ],
   "source": [
    "!cat cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model_fn(hyperparameters):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', name='inputs', input_shape=(HEIGHT, WIDTH, DEPTH)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    opt = RMSPropOptimizer(learning_rate=hyperparameters['learning_rate'], decay=hyperparameters['decay'])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    # Notice that the input placeholder has the same input shape as the Keras model input\n",
    "    tensor = tf.placeholder(tf.float32, shape=[None, HEIGHT, WIDTH, DEPTH])\n",
    "    \n",
    "    # The inputs key INPUT_TENSOR_NAME matches the Keras InputLayer name\n",
    "    inputs = {INPUT_TENSOR_NAME: tensor}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "\n",
    "def train_input_fn(training_dir, params):\n",
    "    return _input(tf.estimator.ModeKeys.TRAIN,\n",
    "                    batch_size=BATCH_SIZE, data_dir=training_dir)\n",
    "\n",
    "\n",
    "def eval_input_fn(training_dir, params):\n",
    "    return _input(tf.estimator.ModeKeys.EVAL,\n",
    "                    batch_size=BATCH_SIZE, data_dir=training_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow py2 container will be deprecated soon.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-05 22:35:23 Starting - Starting the training job...\n",
      "2019-06-05 22:35:25 Starting - Launching requested ML instances......\n",
      "2019-06-05 22:36:27 Starting - Preparing the instances for training...\n",
      "2019-06-05 22:37:09 Downloading - Downloading input data...\n",
      "2019-06-05 22:37:50 Training - Training image download completed. Training in progress..\n",
      "\u001b[31m2019-06-05 22:37:44,613 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:44,613 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:44,629 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-22-35-22-786/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:47,302 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:47,302 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:47,302 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:47,302 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:47,302 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:47,303 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:47,303 INFO - tf_container - invoking the user-provided keras_model_fn\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:47,576 INFO - tensorflow - Using the Keras model provided.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:49,292 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f47a80bf590>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[31mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[31mallow_soft_placement: true\u001b[0m\n",
      "\u001b[31mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-22-35-22-786/checkpoints', '_master': ''}\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:49,310 INFO - tensorflow - Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:49,310 INFO - tensorflow - Skip starting Tensorflow server as there is only one node in the cluster.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:49,427 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:50,103 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:50,103 INFO - tensorflow - Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u's3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-22-35-22-786/checkpoints/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:50,103 INFO - tensorflow - Warm-starting from: (u's3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-22-35-22-786/checkpoints/keras/keras_model.ckpt',)\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:50,103 INFO - tensorflow - Warm-starting variable: conv2d_2/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:50,245 INFO - tensorflow - Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:50,437 INFO - tensorflow - Warm-starting variable: conv2d_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:50,606 INFO - tensorflow - Warm-starting variable: dense/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:50,756 INFO - tensorflow - Warm-starting variable: conv2d_3/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:50,900 INFO - tensorflow - Warm-starting variable: dense/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:51,077 INFO - tensorflow - Warm-starting variable: inputs/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:51,219 INFO - tensorflow - Warm-starting variable: conv2d_4/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:51,400 INFO - tensorflow - Warm-starting variable: inputs/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:51,535 INFO - tensorflow - Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:51,678 INFO - tensorflow - Warm-starting variable: conv2d_3/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:51,815 INFO - tensorflow - Warm-starting variable: conv2d/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:51,952 INFO - tensorflow - Warm-starting variable: conv2d_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:52,129 INFO - tensorflow - Warm-starting variable: conv2d_2/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:52,289 INFO - tensorflow - Warm-starting variable: conv2d_4/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:52,470 INFO - tensorflow - Warm-starting variable: conv2d/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:52,613 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:53,036 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:54,214 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:54,224 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:37:54,798 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-22-35-22-786/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:02,573 INFO - tensorflow - loss = 2.314098, step = 1\u001b[0m\n",
      "\n",
      "2019-06-05 22:38:21 Uploading - Uploading generated training model\u001b[31m2019-06-05 22:38:12,192 INFO - tensorflow - Saving checkpoints for 100 into s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-22-35-22-786/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:13,168 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:13,329 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:13,347 INFO - tensorflow - Starting evaluation at 2019-06-05-22:38:13\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:13,531 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:13,586 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-22-35-22-786/checkpoints/model.ckpt-100\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:13,853 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:13,864 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,045 INFO - tensorflow - Evaluation [2/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,105 INFO - tensorflow - Evaluation [4/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,165 INFO - tensorflow - Evaluation [6/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,225 INFO - tensorflow - Evaluation [8/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,284 INFO - tensorflow - Evaluation [10/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,345 INFO - tensorflow - Evaluation [12/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,405 INFO - tensorflow - Evaluation [14/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,464 INFO - tensorflow - Evaluation [16/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,524 INFO - tensorflow - Evaluation [18/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,587 INFO - tensorflow - Evaluation [20/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,613 INFO - tensorflow - Finished evaluation at 2019-06-05-22:38:14\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,613 INFO - tensorflow - Saving dict for global step 100: accuracy = 0.18374999, global_step = 100, loss = 2.2872863\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:14,887 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 100: s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-22-35-22-786/checkpoints/model.ckpt-100\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:15,171 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:15,304 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:15,305 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:15,305 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:15,305 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:15,305 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:15,305 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:15,395 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-22-35-22-786/checkpoints/model.ckpt-100\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:15,764 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1046: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:15,765 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:15,765 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:16,274 INFO - tensorflow - SavedModel written to: s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-22-35-22-786/checkpoints/export/Servo/1559774294/saved_model.pb\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:16,468 INFO - tensorflow - Loss for final step: 2.300068.\u001b[0m\n",
      "\u001b[31m2019-06-05 22:38:16,646 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1559774294\u001b[0m\n",
      "\n",
      "2019-06-05 22:38:26 Completed - Training job completed\n",
      "Billable seconds: 77\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(entry_point='cifar10_cnn.py',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       hyperparameters={'learning_rate': 1e-4, 'decay':1e-6},\n",
    "                       training_steps=100, evaluation_steps=20,\n",
    "                       train_instance_count=1, train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Python 2 tensorflow images will be soon deprecated and may not be supported for newer upcoming versions of the tensorflow images.\n",
      "Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': {'activation_7': {'dtype': 1,\n",
       "   'tensor_shape': {'dim': [{'size': 1}, {'size': 10}]},\n",
       "   'float_val': [0.0962979644536972,\n",
       "    0.10257883369922638,\n",
       "    0.09764635562896729,\n",
       "    0.09731990844011307,\n",
       "    0.09547405689954758,\n",
       "    0.09692122042179108,\n",
       "    0.10776207596063614,\n",
       "    0.10034969449043274,\n",
       "    0.09994587302207947,\n",
       "    0.10570395737886429]}},\n",
       " 'model_spec': {'name': 'generic_model',\n",
       "  'version': {'value': 1559774294},\n",
       "  'signature_name': 'serving_default'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating fake prediction data\n",
    "import numpy as np\n",
    "data = np.random.randn(1, 32, 32, 3)\n",
    "\n",
    "# The inputs key 'inputs_input' matches the Keras InputLayer name\n",
    "predictor.predict({'inputs_input': data}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
