{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "utils.cifar10_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the dataset to an S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='/tmp/cifar10_data', key_prefix='data/DEMO-cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#     Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n",
      "#\r\n",
      "#     Licensed under the Apache License, Version 2.0 (the \"License\").\r\n",
      "#     You may not use this file except in compliance with the License.\r\n",
      "#     A copy of the License is located at\r\n",
      "#    \r\n",
      "#         https://aws.amazon.com/apache-2-0/\r\n",
      "#    \r\n",
      "#     or in the \"license\" file accompanying this file. This file is distributed\r\n",
      "#     on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\r\n",
      "#     express or implied. See the License for the specific language governing\r\n",
      "#     permissions and limitations under the License.\r\n",
      "\r\n",
      "from __future__ import absolute_import\r\n",
      "from __future__ import division\r\n",
      "from __future__ import print_function\r\n",
      "\r\n",
      "import os\r\n",
      "\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.python.keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\r\n",
      "from tensorflow.python.keras.models import Sequential\r\n",
      "from tensorflow.python.saved_model.signature_constants import PREDICT_INPUTS\r\n",
      "from tensorflow.python.training.rmsprop import RMSPropOptimizer\r\n",
      "\r\n",
      "HEIGHT = 32\r\n",
      "WIDTH = 32\r\n",
      "DEPTH = 3\r\n",
      "NUM_CLASSES = 10\r\n",
      "NUM_DATA_BATCHES = 5\r\n",
      "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 10000 * NUM_DATA_BATCHES\r\n",
      "BATCH_SIZE = 128\r\n",
      "INPUT_TENSOR_NAME = 'inputs_input'  # needs to match the name of the first layer + \"_input\"\r\n",
      "\r\n",
      "\r\n",
      "def keras_model_fn(hyperparameters):\r\n",
      "    \"\"\"keras_model_fn receives hyperparameters from the training job and returns a compiled keras model.\r\n",
      "    The model will be transformed into a TensorFlow Estimator before training and it will be saved in a \r\n",
      "    TensorFlow Serving SavedModel at the end of training.\r\n",
      "\r\n",
      "    Args:\r\n",
      "        hyperparameters: The hyperparameters passed to the SageMaker TrainingJob that runs your TensorFlow \r\n",
      "                         training script.\r\n",
      "    Returns: A compiled Keras model\r\n",
      "    \"\"\"\r\n",
      "    model = Sequential()\r\n",
      "\r\n",
      "    model.add(Conv2D(32, (3, 3), padding='same', name='inputs', input_shape=(HEIGHT, WIDTH, DEPTH)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Conv2D(32, (3, 3)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
      "    model.add(Dropout(0.25))\r\n",
      "\r\n",
      "    model.add(Conv2D(64, (3, 3), padding='same'))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Conv2D(64, (3, 3)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
      "    model.add(Dropout(0.25))\r\n",
      "\r\n",
      "    model.add(Flatten())\r\n",
      "    model.add(Dense(512))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Dropout(0.5))\r\n",
      "    model.add(Dense(NUM_CLASSES))\r\n",
      "    model.add(Activation('softmax'))\r\n",
      "    \r\n",
      "    opt = RMSPropOptimizer(learning_rate=hyperparameters['learning_rate'], decay=hyperparameters['decay'])\r\n",
      "\r\n",
      "    model.compile(loss='categorical_crossentropy',\r\n",
      "                  optimizer=opt,\r\n",
      "                  metrics=['accuracy'])\r\n",
      "\r\n",
      "    return model\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn(hyperparameters):\r\n",
      "    \"\"\"This function defines the placeholders that will be added to the model during serving.\r\n",
      "    The function returns a tf.estimator.export.ServingInputReceiver object, which packages the \r\n",
      "    placeholders and the resulting feature Tensors together.\r\n",
      "    For more information: https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/README.rst#creating-a-serving_input_fn\r\n",
      "    \r\n",
      "    Args:\r\n",
      "        hyperparameters: The hyperparameters passed to SageMaker TrainingJob that runs your TensorFlow \r\n",
      "                        training script.\r\n",
      "    Returns: ServingInputReceiver or fn that returns a ServingInputReceiver\r\n",
      "    \"\"\"\r\n",
      "    \r\n",
      "    # Notice that the input placeholder has the same input shape as the Keras model input\r\n",
      "    tensor = tf.placeholder(tf.float32, shape=[None, HEIGHT, WIDTH, DEPTH])\r\n",
      "    \r\n",
      "    # The inputs key INPUT_TENSOR_NAME matches the Keras InputLayer name\r\n",
      "    inputs = {INPUT_TENSOR_NAME: tensor}\r\n",
      "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, hyperparameters):\r\n",
      "    \"\"\"Returns input function that would feed the model during training\"\"\"\r\n",
      "    return _input(tf.estimator.ModeKeys.TRAIN,\r\n",
      "                    batch_size=BATCH_SIZE, data_dir=training_dir)\r\n",
      "\r\n",
      "\r\n",
      "def eval_input_fn(training_dir, hyperparameters):\r\n",
      "    \"\"\"Returns input function that would feed the model during evaluation\"\"\"\r\n",
      "    return _input(tf.estimator.ModeKeys.EVAL,\r\n",
      "                    batch_size=BATCH_SIZE, data_dir=training_dir)\r\n",
      "\r\n",
      "\r\n",
      "def _input(mode, batch_size, data_dir):\r\n",
      "    \"\"\"Uses the tf.data input pipeline for CIFAR-10 dataset.\r\n",
      "    Args:\r\n",
      "        mode: Standard names for model modes (tf.estimators.ModeKeys).\r\n",
      "        batch_size: The number of samples per batch of input requested.\r\n",
      "    \"\"\"\r\n",
      "    dataset = _record_dataset(_filenames(mode, data_dir))\r\n",
      "\r\n",
      "    # For training repeat forever.\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        dataset = dataset.repeat()\r\n",
      "\r\n",
      "    dataset = dataset.map(_dataset_parser)\r\n",
      "    dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "    # For training, preprocess the image and shuffle.\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        dataset = dataset.map(_train_preprocess_fn)\r\n",
      "        dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "        # Ensure that the capacity is sufficiently large to provide good random\r\n",
      "        # shuffling.\r\n",
      "        buffer_size = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4) + 3 * batch_size\r\n",
      "        dataset = dataset.shuffle(buffer_size=buffer_size)\r\n",
      "\r\n",
      "    # Subtract off the mean and divide by the variance of the pixels.\r\n",
      "    dataset = dataset.map(\r\n",
      "        lambda image, label: (tf.image.per_image_standardization(image), label))\r\n",
      "    dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "    # Batch results by up to batch_size, and then fetch the tuple from the\r\n",
      "    # iterator.\r\n",
      "    iterator = dataset.batch(batch_size).make_one_shot_iterator()\r\n",
      "    images, labels = iterator.get_next()\r\n",
      "\r\n",
      "    # We must use the default input tensor name PREDICT_INPUTS\r\n",
      "    return {INPUT_TENSOR_NAME: images}, labels\r\n",
      "\r\n",
      "\r\n",
      "def _train_preprocess_fn(image, label):\r\n",
      "    \"\"\"Preprocess a single training image of layout [height, width, depth].\"\"\"\r\n",
      "    # Resize the image to add four extra pixels on each side.\r\n",
      "    image = tf.image.resize_image_with_crop_or_pad(image, HEIGHT + 8, WIDTH + 8)\r\n",
      "\r\n",
      "    # Randomly crop a [HEIGHT, WIDTH] section of the image.\r\n",
      "    image = tf.random_crop(image, [HEIGHT, WIDTH, DEPTH])\r\n",
      "\r\n",
      "    # Randomly flip the image horizontally.\r\n",
      "    image = tf.image.random_flip_left_right(image)\r\n",
      "\r\n",
      "    return image, label\r\n",
      "\r\n",
      "\r\n",
      "def _dataset_parser(value):\r\n",
      "    \"\"\"Parse a CIFAR-10 record from value.\"\"\"\r\n",
      "    # Every record consists of a label followed by the image, with a fixed number\r\n",
      "    # of bytes for each.\r\n",
      "    label_bytes = 1\r\n",
      "    image_bytes = HEIGHT * WIDTH * DEPTH\r\n",
      "    record_bytes = label_bytes + image_bytes\r\n",
      "\r\n",
      "    # Convert from a string to a vector of uint8 that is record_bytes long.\r\n",
      "    raw_record = tf.decode_raw(value, tf.uint8)\r\n",
      "\r\n",
      "    # The first byte represents the label, which we convert from uint8 to int32.\r\n",
      "    label = tf.cast(raw_record[0], tf.int32)\r\n",
      "\r\n",
      "    # The remaining bytes after the label represent the image, which we reshape\r\n",
      "    # from [depth * height * width] to [depth, height, width].\r\n",
      "    depth_major = tf.reshape(raw_record[label_bytes:record_bytes],\r\n",
      "                             [DEPTH, HEIGHT, WIDTH])\r\n",
      "\r\n",
      "    # Convert from [depth, height, width] to [height, width, depth], and cast as\r\n",
      "    # float32.\r\n",
      "    image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\r\n",
      "\r\n",
      "    return image, tf.one_hot(label, NUM_CLASSES)\r\n",
      "\r\n",
      "\r\n",
      "def _record_dataset(filenames):\r\n",
      "    \"\"\"Returns an input pipeline Dataset from `filenames`.\"\"\"\r\n",
      "    record_bytes = HEIGHT * WIDTH * DEPTH + 1\r\n",
      "    return tf.data.FixedLengthRecordDataset(filenames, record_bytes)\r\n",
      "\r\n",
      "\r\n",
      "def _filenames(mode, data_dir):\r\n",
      "    \"\"\"Returns a list of filenames based on 'mode'.\"\"\"\r\n",
      "    data_dir = os.path.join(data_dir, 'cifar-10-batches-bin')\r\n",
      "\r\n",
      "    assert os.path.exists(data_dir), ('Run cifar10_download_and_extract.py first '\r\n",
      "                                      'to download and extract the CIFAR-10 data.')\r\n",
      "\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        return [\r\n",
      "            os.path.join(data_dir, 'data_batch_%d.bin' % i)\r\n",
      "            for i in range(1, NUM_DATA_BATCHES + 1)\r\n",
      "        ]\r\n",
      "    elif mode == tf.estimator.ModeKeys.EVAL:\r\n",
      "        return [os.path.join(data_dir, 'test_batch.bin')]\r\n",
      "    else:\r\n",
      "        raise ValueError('Invalid mode: %s' % mode)\r\n"
     ]
    }
   ],
   "source": [
    "!cat cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model_fn(hyperparameters):\n",
    "    \"\"\"keras_model_fn receives hyperparameters from the training job and returns a compiled keras model.\n",
    "    The model will be transformed into a TensorFlow Estimator before training and it will be saved in a \n",
    "    TensorFlow Serving SavedModel at the end of training.\n",
    "\n",
    "    Args:\n",
    "        hyperparameters: The hyperparameters passed to the SageMaker TrainingJob that runs your TensorFlow \n",
    "                         training script.\n",
    "    Returns: A compiled Keras model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', name='inputs', input_shape=(HEIGHT, WIDTH, DEPTH)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    opt = RMSPropOptimizer(learning_rate=hyperparameters['learning_rate'], decay=hyperparameters['decay'])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    # Notice that the input placeholder has the same input shape as the Keras model input\n",
    "    tensor = tf.placeholder(tf.float32, shape=[None, HEIGHT, WIDTH, DEPTH])\n",
    "    \n",
    "    # The inputs key INPUT_TENSOR_NAME matches the Keras InputLayer name\n",
    "    inputs = {INPUT_TENSOR_NAME: tensor}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "\n",
    "def train_input_fn(training_dir, params):\n",
    "    return _input(tf.estimator.ModeKeys.TRAIN,\n",
    "                    batch_size=BATCH_SIZE, data_dir=training_dir)\n",
    "\n",
    "\n",
    "def eval_input_fn(training_dir, params):\n",
    "    return _input(tf.estimator.ModeKeys.EVAL,\n",
    "                    batch_size=BATCH_SIZE, data_dir=training_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow py2 container will be deprecated soon.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-05 21:52:22 Starting - Starting the training job...\n",
      "2019-06-05 21:52:25 Starting - Launching requested ML instances......\n",
      "2019-06-05 21:53:29 Starting - Preparing the instances for training...\n",
      "2019-06-05 21:54:20 Downloading - Downloading input data...\n",
      "2019-06-05 21:54:41 Training - Downloading the training image.\n",
      "\u001b[31m2019-06-05 21:54:54,503 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:54,503 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:54,516 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-21-52-21-987/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:57,267 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:57,267 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:57,267 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:57,267 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:57,267 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:57,268 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:57,268 INFO - tf_container - invoking the user-provided keras_model_fn\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:57,520 INFO - tensorflow - Using the Keras model provided.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:59,158 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f011867d590>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[31mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[31mallow_soft_placement: true\u001b[0m\n",
      "\u001b[31mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-21-52-21-987/checkpoints', '_master': ''}\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:59,176 INFO - tensorflow - Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:59,176 INFO - tensorflow - Skip starting Tensorflow server as there is only one node in the cluster.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:59,299 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:59,913 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:59,913 INFO - tensorflow - Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u's3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-21-52-21-987/checkpoints/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:59,913 INFO - tensorflow - Warm-starting from: (u's3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-21-52-21-987/checkpoints/keras/keras_model.ckpt',)\u001b[0m\n",
      "\u001b[31m2019-06-05 21:54:59,914 INFO - tensorflow - Warm-starting variable: conv2d_2/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:00,054 INFO - tensorflow - Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:00,241 INFO - tensorflow - Warm-starting variable: conv2d_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:00,373 INFO - tensorflow - Warm-starting variable: dense/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:00,494 INFO - tensorflow - Warm-starting variable: dense/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:00,647 INFO - tensorflow - Warm-starting variable: inputs/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:00,800 INFO - tensorflow - Warm-starting variable: inputs/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:00,950 INFO - tensorflow - Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:01,083 INFO - tensorflow - Warm-starting variable: conv2d/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:01,223 INFO - tensorflow - Warm-starting variable: conv2d_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:01,348 INFO - tensorflow - Warm-starting variable: conv2d_2/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:01,489 INFO - tensorflow - Warm-starting variable: conv2d/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:01,634 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:02,089 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:02,922 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:02,934 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:03,443 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-21-52-21-987/checkpoints/model.ckpt.\u001b[0m\n",
      "\n",
      "2019-06-05 21:55:09 Training - Training image download completed. Training in progress.\u001b[31m2019-06-05 21:55:11,945 INFO - tensorflow - loss = 2.3470285, step = 1\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:36,197 INFO - tensorflow - Saving checkpoints for 100 into s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-21-52-21-987/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:37,300 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:37,435 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:37,454 INFO - tensorflow - Starting evaluation at 2019-06-05-21:55:37\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:37,538 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:37,622 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-21-52-21-987/checkpoints/model.ckpt-100\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:37,823 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:37,836 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:38,112 INFO - tensorflow - Evaluation [2/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:38,269 INFO - tensorflow - Evaluation [4/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:38,429 INFO - tensorflow - Evaluation [6/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:38,586 INFO - tensorflow - Evaluation [8/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:38,742 INFO - tensorflow - Evaluation [10/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:38,901 INFO - tensorflow - Evaluation [12/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:39,057 INFO - tensorflow - Evaluation [14/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:39,212 INFO - tensorflow - Evaluation [16/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:39,367 INFO - tensorflow - Evaluation [18/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:39,522 INFO - tensorflow - Evaluation [20/20]\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:39,549 INFO - tensorflow - Finished evaluation at 2019-06-05-21:55:39\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:39,549 INFO - tensorflow - Saving dict for global step 100: accuracy = 0.278125, global_step = 100, loss = 2.0213704\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:39,897 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 100: s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-21-52-21-987/checkpoints/model.ckpt-100\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:40,158 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:40,264 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:40,265 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:40,265 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:40,265 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:40,265 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:40,265 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:40,347 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-21-52-21-987/checkpoints/model.ckpt-100\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:40,622 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1046: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:40,622 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:40,622 INFO - tensorflow - No assets to write.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-06-05 21:55:51 Uploading - Uploading generated training model\n",
      "2019-06-05 21:55:51 Completed - Training job completed\n",
      "\u001b[31m2019-06-05 21:55:41,299 INFO - tensorflow - SavedModel written to: s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-05-21-52-21-987/checkpoints/export/Servo/1559771739/saved_model.pb\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:41,531 INFO - tensorflow - Loss for final step: 2.0027168.\u001b[0m\n",
      "\u001b[31m2019-06-05 21:55:41,762 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1559771739\u001b[0m\n",
      "Billable seconds: 92\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(entry_point='cifar10_cnn.py',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       hyperparameters={'learning_rate': 1e-4, 'decay':1e-6},\n",
    "                       training_steps=100, evaluation_steps=20,\n",
    "                       train_instance_count=1, train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Python 2 tensorflow images will be soon deprecated and may not be supported for newer upcoming versions of the tensorflow images.\n",
      "Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': {'activation_5': {'dtype': 1,\n",
       "   'tensor_shape': {'dim': [{'size': 1}, {'size': 10}]},\n",
       "   'float_val': [0.0754556804895401,\n",
       "    0.10899032652378082,\n",
       "    0.10963528603315353,\n",
       "    0.08571675419807434,\n",
       "    0.11828980594873428,\n",
       "    0.08781439065933228,\n",
       "    0.12763580679893494,\n",
       "    0.11712240427732468,\n",
       "    0.05176696926355362,\n",
       "    0.1175726130604744]}},\n",
       " 'model_spec': {'name': 'generic_model',\n",
       "  'version': {'value': 1559771739},\n",
       "  'signature_name': 'serving_default'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating fake prediction data\n",
    "import numpy as np\n",
    "data = np.random.randn(1, 32, 32, 3)\n",
    "\n",
    "# The inputs key 'inputs_input' matches the Keras InputLayer name\n",
    "predictor.predict({'inputs_input': data}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
