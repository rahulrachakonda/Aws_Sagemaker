{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Host a Keras Sequential Model\n",
    "\n",
    "This notebook shows how to train and host a Keras Sequential model on SageMaker. The model used for this notebook is a simple deep CNN that was extracted from [the Keras examples](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is one of the most popular machine learning datasets. It consists of 60,000 32x32 images belonging to 10 different classes (6,000 images per class). Here are the classes in the dataset, as well as 10 random images from each:\n",
    "\n",
    "![cifar10](https://maet3608.github.io/nuts-ml/_images/cifar10.png)\n",
    "\n",
    "In this tutorial, we will train a deep CNN to recognize these images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the CIFAR-10 dataset\n",
    "Downloading the test and training data will take around 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar dataset already downloaded\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "utils.cifar10_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the dataset to an S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='/tmp/cifar10_data', key_prefix='data/DEMO-cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sagemaker_session.upload_data` will upload the CIFAR-10 dataset from this machine to a bucket named **sagemaker-{region}-{*your aws account number*}**, if you don't have this bucket yet, `sagemaker_session` will create it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete source code\n",
    "Here is the full source code for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#     Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n",
      "#\r\n",
      "#     Licensed under the Apache License, Version 2.0 (the \"License\").\r\n",
      "#     You may not use this file except in compliance with the License.\r\n",
      "#     A copy of the License is located at\r\n",
      "#    \r\n",
      "#         https://aws.amazon.com/apache-2-0/\r\n",
      "#    \r\n",
      "#     or in the \"license\" file accompanying this file. This file is distributed\r\n",
      "#     on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\r\n",
      "#     express or implied. See the License for the specific language governing\r\n",
      "#     permissions and limitations under the License.\r\n",
      "\r\n",
      "from __future__ import absolute_import\r\n",
      "from __future__ import division\r\n",
      "from __future__ import print_function\r\n",
      "\r\n",
      "import os\r\n",
      "\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.python.keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\r\n",
      "from tensorflow.python.keras.models import Sequential\r\n",
      "from tensorflow.python.saved_model.signature_constants import PREDICT_INPUTS\r\n",
      "from tensorflow.python.training.rmsprop import RMSPropOptimizer\r\n",
      "\r\n",
      "HEIGHT = 32\r\n",
      "WIDTH = 32\r\n",
      "DEPTH = 3\r\n",
      "NUM_CLASSES = 10\r\n",
      "NUM_DATA_BATCHES = 5\r\n",
      "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 10000 * NUM_DATA_BATCHES\r\n",
      "BATCH_SIZE = 128\r\n",
      "INPUT_TENSOR_NAME = 'inputs_input'  # needs to match the name of the first layer + \"_input\"\r\n",
      "\r\n",
      "\r\n",
      "def keras_model_fn(hyperparameters):\r\n",
      "    \"\"\"keras_model_fn receives hyperparameters from the training job and returns a compiled keras model.\r\n",
      "    The model will be transformed into a TensorFlow Estimator before training and it will be saved in a \r\n",
      "    TensorFlow Serving SavedModel at the end of training.\r\n",
      "\r\n",
      "    Args:\r\n",
      "        hyperparameters: The hyperparameters passed to the SageMaker TrainingJob that runs your TensorFlow \r\n",
      "                         training script.\r\n",
      "    Returns: A compiled Keras model\r\n",
      "    \"\"\"\r\n",
      "    model = Sequential()\r\n",
      "\r\n",
      "    model.add(Conv2D(32, (3, 3), padding='same', name='inputs', input_shape=(HEIGHT, WIDTH, DEPTH)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Conv2D(32, (3, 3)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
      "    model.add(Dropout(0.25))\r\n",
      "\r\n",
      "    model.add(Conv2D(64, (3, 3), padding='same'))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Conv2D(64, (3, 3)))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
      "    model.add(Dropout(0.25))\r\n",
      "\r\n",
      "    model.add(Flatten())\r\n",
      "    model.add(Dense(512))\r\n",
      "    model.add(Activation('relu'))\r\n",
      "    model.add(Dropout(0.5))\r\n",
      "    model.add(Dense(NUM_CLASSES))\r\n",
      "    model.add(Activation('softmax'))\r\n",
      "    \r\n",
      "    opt = RMSPropOptimizer(learning_rate=hyperparameters['learning_rate'], decay=hyperparameters['decay'])\r\n",
      "\r\n",
      "    model.compile(loss='categorical_crossentropy',\r\n",
      "                  optimizer=opt,\r\n",
      "                  metrics=['accuracy'])\r\n",
      "\r\n",
      "    return model\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn(hyperparameters):\r\n",
      "    \"\"\"This function defines the placeholders that will be added to the model during serving.\r\n",
      "    The function returns a tf.estimator.export.ServingInputReceiver object, which packages the \r\n",
      "    placeholders and the resulting feature Tensors together.\r\n",
      "    For more information: https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/README.rst#creating-a-serving_input_fn\r\n",
      "    \r\n",
      "    Args:\r\n",
      "        hyperparameters: The hyperparameters passed to SageMaker TrainingJob that runs your TensorFlow \r\n",
      "                        training script.\r\n",
      "    Returns: ServingInputReceiver or fn that returns a ServingInputReceiver\r\n",
      "    \"\"\"\r\n",
      "    \r\n",
      "    # Notice that the input placeholder has the same input shape as the Keras model input\r\n",
      "    tensor = tf.placeholder(tf.float32, shape=[None, HEIGHT, WIDTH, DEPTH])\r\n",
      "    \r\n",
      "    # The inputs key INPUT_TENSOR_NAME matches the Keras InputLayer name\r\n",
      "    inputs = {INPUT_TENSOR_NAME: tensor}\r\n",
      "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, hyperparameters):\r\n",
      "    \"\"\"Returns input function that would feed the model during training\"\"\"\r\n",
      "    return _input(tf.estimator.ModeKeys.TRAIN,\r\n",
      "                    batch_size=BATCH_SIZE, data_dir=training_dir)\r\n",
      "\r\n",
      "\r\n",
      "def eval_input_fn(training_dir, hyperparameters):\r\n",
      "    \"\"\"Returns input function that would feed the model during evaluation\"\"\"\r\n",
      "    return _input(tf.estimator.ModeKeys.EVAL,\r\n",
      "                    batch_size=BATCH_SIZE, data_dir=training_dir)\r\n",
      "\r\n",
      "\r\n",
      "def _input(mode, batch_size, data_dir):\r\n",
      "    \"\"\"Uses the tf.data input pipeline for CIFAR-10 dataset.\r\n",
      "    Args:\r\n",
      "        mode: Standard names for model modes (tf.estimators.ModeKeys).\r\n",
      "        batch_size: The number of samples per batch of input requested.\r\n",
      "    \"\"\"\r\n",
      "    dataset = _record_dataset(_filenames(mode, data_dir))\r\n",
      "\r\n",
      "    # For training repeat forever.\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        dataset = dataset.repeat()\r\n",
      "\r\n",
      "    dataset = dataset.map(_dataset_parser)\r\n",
      "    dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "    # For training, preprocess the image and shuffle.\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        dataset = dataset.map(_train_preprocess_fn)\r\n",
      "        dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "        # Ensure that the capacity is sufficiently large to provide good random\r\n",
      "        # shuffling.\r\n",
      "        buffer_size = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * 0.4) + 3 * batch_size\r\n",
      "        dataset = dataset.shuffle(buffer_size=buffer_size)\r\n",
      "\r\n",
      "    # Subtract off the mean and divide by the variance of the pixels.\r\n",
      "    dataset = dataset.map(\r\n",
      "        lambda image, label: (tf.image.per_image_standardization(image), label))\r\n",
      "    dataset.prefetch(2 * batch_size)\r\n",
      "\r\n",
      "    # Batch results by up to batch_size, and then fetch the tuple from the\r\n",
      "    # iterator.\r\n",
      "    iterator = dataset.batch(batch_size).make_one_shot_iterator()\r\n",
      "    images, labels = iterator.get_next()\r\n",
      "\r\n",
      "    # We must use the default input tensor name PREDICT_INPUTS\r\n",
      "    return {INPUT_TENSOR_NAME: images}, labels\r\n",
      "\r\n",
      "\r\n",
      "def _train_preprocess_fn(image, label):\r\n",
      "    \"\"\"Preprocess a single training image of layout [height, width, depth].\"\"\"\r\n",
      "    # Resize the image to add four extra pixels on each side.\r\n",
      "    image = tf.image.resize_image_with_crop_or_pad(image, HEIGHT + 8, WIDTH + 8)\r\n",
      "\r\n",
      "    # Randomly crop a [HEIGHT, WIDTH] section of the image.\r\n",
      "    image = tf.random_crop(image, [HEIGHT, WIDTH, DEPTH])\r\n",
      "\r\n",
      "    # Randomly flip the image horizontally.\r\n",
      "    image = tf.image.random_flip_left_right(image)\r\n",
      "\r\n",
      "    return image, label\r\n",
      "\r\n",
      "\r\n",
      "def _dataset_parser(value):\r\n",
      "    \"\"\"Parse a CIFAR-10 record from value.\"\"\"\r\n",
      "    # Every record consists of a label followed by the image, with a fixed number\r\n",
      "    # of bytes for each.\r\n",
      "    label_bytes = 1\r\n",
      "    image_bytes = HEIGHT * WIDTH * DEPTH\r\n",
      "    record_bytes = label_bytes + image_bytes\r\n",
      "\r\n",
      "    # Convert from a string to a vector of uint8 that is record_bytes long.\r\n",
      "    raw_record = tf.decode_raw(value, tf.uint8)\r\n",
      "\r\n",
      "    # The first byte represents the label, which we convert from uint8 to int32.\r\n",
      "    label = tf.cast(raw_record[0], tf.int32)\r\n",
      "\r\n",
      "    # The remaining bytes after the label represent the image, which we reshape\r\n",
      "    # from [depth * height * width] to [depth, height, width].\r\n",
      "    depth_major = tf.reshape(raw_record[label_bytes:record_bytes],\r\n",
      "                             [DEPTH, HEIGHT, WIDTH])\r\n",
      "\r\n",
      "    # Convert from [depth, height, width] to [height, width, depth], and cast as\r\n",
      "    # float32.\r\n",
      "    image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\r\n",
      "\r\n",
      "    return image, tf.one_hot(label, NUM_CLASSES)\r\n",
      "\r\n",
      "\r\n",
      "def _record_dataset(filenames):\r\n",
      "    \"\"\"Returns an input pipeline Dataset from `filenames`.\"\"\"\r\n",
      "    record_bytes = HEIGHT * WIDTH * DEPTH + 1\r\n",
      "    return tf.data.FixedLengthRecordDataset(filenames, record_bytes)\r\n",
      "\r\n",
      "\r\n",
      "def _filenames(mode, data_dir):\r\n",
      "    \"\"\"Returns a list of filenames based on 'mode'.\"\"\"\r\n",
      "    data_dir = os.path.join(data_dir, 'cifar-10-batches-bin')\r\n",
      "\r\n",
      "    assert os.path.exists(data_dir), ('Run cifar10_download_and_extract.py first '\r\n",
      "                                      'to download and extract the CIFAR-10 data.')\r\n",
      "\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        return [\r\n",
      "            os.path.join(data_dir, 'data_batch_%d.bin' % i)\r\n",
      "            for i in range(1, NUM_DATA_BATCHES + 1)\r\n",
      "        ]\r\n",
      "    elif mode == tf.estimator.ModeKeys.EVAL:\r\n",
      "        return [os.path.join(data_dir, 'test_batch.bin')]\r\n",
      "    else:\r\n",
      "        raise ValueError('Invalid mode: %s' % mode)\r\n"
     ]
    }
   ],
   "source": [
    "!cat cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a closer look:\n",
    "\n",
    "### The model function\n",
    "This function constitutes the main difference between TensorFlow and Keras models on SageMaker; Keras models have a `keras_model_fn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model_fn(hyperparameters):\n",
    "    \"\"\"keras_model_fn receives hyperparameters from the training job and returns a compiled keras model.\n",
    "    The model will be transformed into a TensorFlow Estimator before training and it will be saved in a \n",
    "    TensorFlow Serving SavedModel at the end of training.\n",
    "\n",
    "    Args:\n",
    "        hyperparameters: The hyperparameters passed to the SageMaker TrainingJob that runs your TensorFlow \n",
    "                         training script.\n",
    "    Returns: A compiled Keras model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', name='inputs', input_shape=(HEIGHT, WIDTH, DEPTH)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    opt = RMSPropOptimizer(learning_rate=hyperparameters['learning_rate'], decay=hyperparameters['decay'])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function builds and returns a compiled Keras model.\n",
    "\n",
    "**Note:** The first layer is named `PREDICT_INPUTS`. This serves as a workaround for a known issue where TensorFlow does not recognize the default (or any custom) name for the first layer of Keras models. Furthermore, note that we are wrapping our model in a `tf.keras.Model` before returning it. This serves as a workaround for a known issue where a Sequential model cannot be directly converted into an Estimator. See [here](https://github.com/tensorflow/tensorflow/issues/20552) for more information about the issue.\n",
    "\n",
    "### Input functions\n",
    "These functions are similar to those required by any other model using the TensorFlow Estimator API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn(params):\n",
    "    # Notice that the input placeholder has the same input shape as the Keras model input\n",
    "    tensor = tf.placeholder(tf.float32, shape=[None, HEIGHT, WIDTH, DEPTH])\n",
    "    \n",
    "    # The inputs key INPUT_TENSOR_NAME matches the Keras InputLayer name\n",
    "    inputs = {INPUT_TENSOR_NAME: tensor}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "\n",
    "def train_input_fn(training_dir, params):\n",
    "    return _input(tf.estimator.ModeKeys.TRAIN,\n",
    "                    batch_size=BATCH_SIZE, data_dir=training_dir)\n",
    "\n",
    "\n",
    "def eval_input_fn(training_dir, params):\n",
    "    return _input(tf.estimator.ModeKeys.EVAL,\n",
    "                    batch_size=BATCH_SIZE, data_dir=training_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train_` and `eval_` functions call the `_input` function which returns a properly processed and shuffled (for training) set of images and labels.\n",
    "\n",
    "## Create a training job using the SageMaker TensorFlow Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow py2 container will be deprecated soon.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-04 22:10:45 Starting - Starting the training job...\n",
      "2019-06-04 22:10:47 Starting - Launching requested ML instances......\n",
      "2019-06-04 22:11:52 Starting - Preparing the instances for training......\n",
      "2019-06-04 22:13:12 Downloading - Downloading input data\n",
      "2019-06-04 22:13:12 Training - Training image download completed. Training in progress..\n",
      "\u001b[31m2019-06-04 22:13:13,168 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:13,169 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:13,183 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-04-22-10-44-884/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:16,135 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:16,135 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:16,135 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:16,135 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:16,135 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:16,135 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:16,136 INFO - tf_container - invoking the user-provided keras_model_fn\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:16,369 INFO - tensorflow - Using the Keras model provided.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:18,070 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f64ecf31590>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[31mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[31mallow_soft_placement: true\u001b[0m\n",
      "\u001b[31mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[31m}\u001b[0m\n",
      "\u001b[31m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-04-22-10-44-884/checkpoints', '_master': ''}\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:18,124 INFO - tensorflow - Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:18,125 INFO - tensorflow - Skip starting Tensorflow server as there is only one node in the cluster.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:18,254 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:18,822 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:18,822 INFO - tensorflow - Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u's3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-04-22-10-44-884/checkpoints/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:18,822 INFO - tensorflow - Warm-starting from: (u's3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-04-22-10-44-884/checkpoints/keras/keras_model.ckpt',)\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:18,823 INFO - tensorflow - Warm-starting variable: conv2d_2/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:18,970 INFO - tensorflow - Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:19,106 INFO - tensorflow - Warm-starting variable: conv2d_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:19,248 INFO - tensorflow - Warm-starting variable: dense/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:19,381 INFO - tensorflow - Warm-starting variable: dense/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:19,521 INFO - tensorflow - Warm-starting variable: inputs/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:19,686 INFO - tensorflow - Warm-starting variable: inputs/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:19,825 INFO - tensorflow - Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:19,960 INFO - tensorflow - Warm-starting variable: conv2d/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:20,134 INFO - tensorflow - Warm-starting variable: conv2d_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:20,275 INFO - tensorflow - Warm-starting variable: conv2d_2/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:20,419 INFO - tensorflow - Warm-starting variable: conv2d/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:20,570 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:20,989 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:21,883 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:21,892 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:22,389 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-04-22-10-44-884/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:30,640 INFO - tensorflow - loss = 2.388275, step = 1\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:53,482 INFO - tensorflow - Saving checkpoints for 100 into s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-04-22-10-44-884/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:54,587 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:54,716 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:54,735 INFO - tensorflow - Starting evaluation at 2019-06-04-22:13:54\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:54,826 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:54,878 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-04-22-10-44-884/checkpoints/model.ckpt-100\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:55,104 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:55,114 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:55,363 INFO - tensorflow - Evaluation [2/20]\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:55,512 INFO - tensorflow - Evaluation [4/20]\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:55,660 INFO - tensorflow - Evaluation [6/20]\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:55,876 INFO - tensorflow - Evaluation [8/20]\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:56,031 INFO - tensorflow - Evaluation [10/20]\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:56,179 INFO - tensorflow - Evaluation [12/20]\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:56,329 INFO - tensorflow - Evaluation [14/20]\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:56,477 INFO - tensorflow - Evaluation [16/20]\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:56,626 INFO - tensorflow - Evaluation [18/20]\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:56,774 INFO - tensorflow - Evaluation [20/20]\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:56,798 INFO - tensorflow - Finished evaluation at 2019-06-04-22:13:56\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:56,798 INFO - tensorflow - Saving dict for global step 100: accuracy = 0.27617186, global_step = 100, loss = 2.0066097\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,085 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 100: s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-04-22-10-44-884/checkpoints/model.ckpt-100\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,368 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,470 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,471 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,471 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,471 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,471 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,471 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,554 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-04-22-10-44-884/checkpoints/model.ckpt-100\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,898 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1046: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,898 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:57,898 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:58,618 INFO - tensorflow - SavedModel written to: s3://sagemaker-us-east-2-180320598215/sagemaker-tensorflow-2019-06-04-22-10-44-884/checkpoints/export/Servo/1559686437/saved_model.pb\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:58,799 INFO - tensorflow - Loss for final step: 2.0605888.\u001b[0m\n",
      "\u001b[31m2019-06-04 22:13:59,034 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1559686437\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-06-04 22:14:09 Uploading - Uploading generated training model\n",
      "2019-06-04 22:14:09 Completed - Training job completed\n",
      "Billable seconds: 83\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(entry_point='cifar10_cnn.py',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       hyperparameters={'learning_rate': 1e-4, 'decay':1e-6},\n",
    "                       training_steps=100, evaluation_steps=20,\n",
    "                       train_instance_count=1, train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Keras models have a known issue and cannot be used for distributed (multi-instance) training. Keep `train_instance_count == 1` until the TensorFlow/Keras team support this feature. See [here](https://github.com/tensorflow/tensorflow/issues/14504) for more information about the issue.\n",
    "\n",
    "\n",
    "## Deploy the trained model\n",
    "\n",
    "The deploy() method creates an endpoint which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some predictions\n",
    "Prediction is not the focus of this notebook, so to verify the endpoint's functionality, we'll simply generate random data in the correct shape and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating fake prediction data\n",
    "import numpy as np\n",
    "data = np.random.randn(1, 32, 32, 3)\n",
    "\n",
    "# The inputs key 'inputs_input' matches the Keras InputLayer name\n",
    "predictor.predict({'inputs_input': data}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up\n",
    "To avoid incurring charges to your AWS account for the resources used in this tutorial you need to delete the SageMaker Endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
